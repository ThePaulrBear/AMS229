{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source localization problem$ \n",
    "% Text formating\n",
    "\\newcommand {\\th}{^{th}} % for ith, jth, etc. \n",
    "% General Latex Definitions\n",
    "\\newcommand {\\vec}{\\mathbf} % Vector variable\n",
    "\\newcommand {\\mat}{} % Matrix variable\n",
    "\\newcommand {\\set}{\\mathcal} % Set name\n",
    "\\newcommand {\\setcomplement }[1]{\\overline{\\set{#1}}}\n",
    "\\newcommand{\\invs}{^{-1}}\n",
    "\\newcommand{\\trans}{^ \\top} % Vector or matrix transpose notation (\\intercal is an alternative)\n",
    "% Text\n",
    "\\newcommand{\\suchthat}{\\mathrel{} \\middle| \\mathrel{} } % Alternative: \\mid\n",
    "\\newcommand {\\definedas}{\\equiv}%alternative{:=}\n",
    "\\newcommand {\\for}{\\text{for}\\;}\n",
    "\\newcommand {\\and}{\\quad \\text{and}\\quad}\n",
    "% \\Scalar functions\n",
    "\\newcommand {\\arctan}{\\tan\\invs}\n",
    "\\newcommand {\\atan}{\\arctan}\n",
    "\\newcommand {\\abs}[1]{|#1|}\n",
    "% Vector Functions\n",
    "\\newcommand {\\innerproduct}[2]{\\langle #1, #2 \\rangle}\n",
    "\\newcommand {\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand {\\onenorm}[1]{\\norm{#1}_{1}}\n",
    "\\newcommand {\\twonorm}[1]{\\norm{#1}_{2}}\n",
    "\\newcommand {\\pnorm}[1]{\\norm{#1}_{p}}\n",
    "\\newcommand {\\inftynorm}[1]{\\norm{#1}_{\\infty}}\n",
    "% Sets\n",
    "\\newcommand {\\reals}{\\mathbb{R}}\n",
    "\\newcommand {\\realsn}{\\reals^{n}}\n",
    "\\newcommand {\\positivereals}{\\reals_{>0}}\n",
    "\\newcommand {\\integers}{\\mathbb{Z}}\n",
    "\\newcommand \\squarematrices[1][n]{\\reals^{#1 \\times #1}}\n",
    "\\newcommand \\symmetricmatrices[1][n]{\\mathbb{S}^{#1}}\n",
    "\\newcommand \\pdmatrices[1][n]{\\symmetricmatrices[#1]_{++}}\n",
    "\\newcommand \\psdmatrices[1][n]{\\symmetricmatrices[#1]_{+}}\n",
    "% Common vectors. If a value is a variable don't use the \"\\\"\n",
    "\\newcommand {\\x}{\\vec x}\n",
    "\\newcommand {\\y}{\\vec y} \n",
    "\\newcommand {\\u}{\\vec u}\n",
    "\\newcommand {\\v}{\\vec v}\n",
    "\\newcommand {\\onevec}{\\mathbb{1}}\n",
    "% Matrix shortcuts\n",
    "\\newcommand {\\beginmatrix}{\\begin{bmatrix}}\n",
    "\\newcommand {\\endmatrix}{\\end{bmatrix}}\n",
    "\\newcommand \\diagmatrix[2]{\n",
    "\\begin{bmatrix} \n",
    "#1 & & \\\\\n",
    "& \\ddots & \\\\\n",
    "& & #2 \\\\\n",
    "\\end{bmatrix}}\n",
    "\\newcommand {\\diag}[1]{D_{#1}}\n",
    "\\newcommand {\\rank}{\\textbf{rank}}\n",
    "\\newcommand {\\trace}[1]{\\textbf{tr}\\(#1\\)} \n",
    "% Calculus\n",
    "\\newcommand {\\derivative}[2]{\\frac{d#1}{d#2}}\n",
    "\\newcommand {\\partialderivative}[2]{\\frac{\\partial#1}{\\partial#2}}\n",
    "\\newcommand {\\ddx}{\\derivative{}{x}}\n",
    "\\newcommand {\\ddt}{\\derivative{}{t}}\n",
    "\\newcommand {\\dxdt}{\\derivative{x}{t}}\n",
    "\\newcommand {\\dydt}{\\derivative{y}{t}}\n",
    "\\newcommand {\\dfdx}{\\derivative{f}{x}}\n",
    "\\newcommand {\\del}{\\nabla}\n",
    "\\newcommand {\\hessian}{\\del^2}\n",
    "% Exponent Taylor Series Definition\n",
    "\\newcommand \\exponentsum[1]{\\sum^\\infty_{k=1} \\frac{#1^k}{k!}}\n",
    "% Brackets and parentheses.\n",
    "\\newcommand {\\(}{\\left(}\n",
    "\\newcommand {\\)}{\\right)}\n",
    "\\newcommand {\\}}{\\right\\}}\n",
    "\\newcommand {\\{}{\\left\\{}\n",
    "\\newcommand {\\beginalign}{\\begin{align}}\n",
    "\\newcommand {\\endalign}{\\end{align}}\n",
    "\\newcommand {\\begincases}{\\begin{cases}}\n",
    "\\newcommand {\\endcases}{\\end{cases}}\n",
    "% Fractions\n",
    "\\newcommand {\\half}{\\frac{1}{2}}\n",
    "\\newcommand {\\third}{\\frac{1}{3}}\n",
    "\\newcommand {\\quarter}{\\frac{1}{4}}\n",
    "% CONVEX OPTIMIZATION\n",
    "\\newcommand \\convexcombo[2]{\\theta #1 + (1 - \\theta)#2}\n",
    "\\newcommand \\minimize[1]{\\underset{#1}{\\text{minimize}}\\quad} % Usage: \\minimize{\\x \\in \\reals}\n",
    "\\newcommand \\maximize[1]{\\underset{#1}{\\text{maximize}}\\quad} % Usage: \\maximize{\\x \\in \\reals}\n",
    "\\newcommand {\\subjectto}{\\text{subject to}\\quad}\n",
    "\\newcommand {\\epi}{\\text{epi}}\n",
    "% DYNAMICAL SYSTEMS\n",
    "% Fixed points\n",
    "\\newcommand {\\xstar}{x^*}\n",
    "\\newcommand {\\mustar}{\\mu^*}\n",
    "\\newcommand {\\xdot}{\\dot{x}}\n",
    "\\newcommand {\\xddot}{\\ddot{x}}\n",
    "\\newcommand {\\ydot}{\\dot{y}}\n",
    "\\newcommand {\\yddot}{\\ddot{y}}\n",
    "% Lagrangian\n",
    "\\newcommand {\\Lagr}{\\mathcal{L}}\n",
    "% Specific AMS229 HW #6\n",
    "\\newcommand {\\g}{\\vec g}\n",
    "\\newcommand {\\r}{\\vec r}\n",
    "\\newcommand {\\a}{\\vec a} \n",
    "\\newcommand{\\nustar}{\\nu^*}\n",
    "\\newcommand{\\gstar}{\\g^*}\n",
    "\\newcommand{\\ystar}{\\y^*}\n",
    "\\newcommand{\\ystartrans}{\\y^{*\\top}}\n",
    "$\n",
    "\n",
    "Consider $m$ sensors at known locations $a_{i}\\in\\mathbb{R}^{n}$ (in practical applications, $n=2$ or $3$). A source located at unknown location $x\\in\\mathbb{R}^{n}$ is emitting signal. From the strength of the signal received by the sensors, it is possible to get noisy measurement of the range $r_{i}$ between the source and the $i$-th sensor:\n",
    "\n",
    "$$r_{i} \\:=\\: \\parallel x - a_{i} \\parallel_{2} \\:+\\: \\varepsilon_{i}, \\quad i=1,...,m,$$\n",
    "\n",
    "where $(\\varepsilon_{1}, ..., \\varepsilon_{m})^{\\top}$ denotes the unknown noise vector. We would like to estimate the source location $x\\in\\mathbb{R}^{n}$ from the noisy measurements $r_{i}>0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we deine a function that will print a numpy matrix as a latex matrix\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "def display_matrix(A, label=None, format='%g'): # Returns the latex code\n",
    "    # 'A' is a numpy matrix\n",
    "    # 'label' is an optional label that will printed before the matrix, with a '=' between.\n",
    "    # 'format' is the string format of each element\n",
    "    # Example usage:    \n",
    "    # display_matrix(A, \"$A$\", format='%.2g');    \n",
    "    # display_matrix(d, format=\"%.4g\");\n",
    "    # Written by Paul Wintz, November 2018.\n",
    "    \n",
    "    row_delimiter = \" \\\\\\\\ \"\n",
    "    column_delimiter = \" & \"\n",
    "    rows = []\n",
    "    \n",
    "    for i in range(A.shape[0]):\n",
    "        row = A[i]\n",
    "        # generate an array with strings\n",
    "        row_arrstr = np.char.mod(format, row)\n",
    "        #combine to a string\n",
    "        rows.append(column_delimiter.join(row_arrstr))\n",
    "\n",
    "    latex = '$\\\\begin{bmatrix}%s\\\\end{bmatrix}$'%(row_delimiter.join(rows))\n",
    "    display(Markdown((label + \" $=$ \" if label else \"\") + latex ))\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) (10+10+10=30 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural way to formulate the source localization problem is to cast it as:\n",
    "\n",
    "$$\\minimize{x\\in\\mathbb{R}^{n}}\\:\\displaystyle\\sum_{i=1}^{m}\\(r_{i} - \\twonorm{ \\x - \\vec a_{i} }\\)^{2},$$\n",
    "\n",
    "or equivalently,\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&\\minimize{\\x\\in\\reals^{n},\\vec g\\in\\reals^{m}} \\sum_{i=1}^{m}\\(r_{i} - g_{i}\\)^{2},\\\\\n",
    "&\\subjectto g_{i}^{2} \\:=\\: \\parallel \\x - \\vec a_{i} \\parallel_{2}^{2}, \\quad i=1,...,m,\n",
    "\\end{aligned}$$\n",
    "\n",
    "which is a nonconvex problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a.1) Use the change of variables \n",
    "\n",
    "$$G := \\begin{pmatrix}g\\\\1\n",
    "\\end{pmatrix}\\left(g^{\\top} \\; 1\\right), \\quad X := \\begin{pmatrix}x\\\\1\n",
    "\\end{pmatrix}\\left(x^{\\top} \\; 1\\right),\n",
    "$$\n",
    "\n",
    "to transcribe the above problem as an optimization problem over the matrix variable pair $(X,G)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Note that\n",
    "\n",
    "$$ G = \\beginmatrix \n",
    "\\g \\g\\trans & \\g \\\\\n",
    "\\g \\trans & 1\n",
    "\\endmatrix \n",
    "= \\beginmatrix \n",
    "g_1^2 & g_1 g_2 & \\cdots & g_1 g_m & g_1 \\\\\n",
    "g_2 g_1 & g_2^2 & \\cdots & g_2 g_m & g_2 \\\\\n",
    "\\vdots &  & \\ddots & \\vdots & \\vdots \\\\\n",
    "g_m g_1 & g_m g_2 & \\cdots & g_m^2 & g_m \\\\\n",
    "g_1 & g_2 & \\cdots & g_m & 1\n",
    "\\endmatrix\n",
    "\\and \n",
    "X = \\beginmatrix \n",
    "\\x \\x\\trans & \\x \\\\\n",
    "\\x \\trans & 1\n",
    "\\endmatrix \n",
    "= \\beginmatrix \n",
    "x_1 x_1 & x_1 x_2 & \\cdots & x_1 x_n & x_1 \\\\\n",
    "x_2 x_1 & x_2 x_2 & \\cdots & x_2 x_n & x_2 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "x_n x_1 & x_n x_2 & \\cdots & x_n x_n & x_n \\\\\n",
    "x_1 & x_2 & \\cdots & x_n & 1\n",
    "\\endmatrix$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take the matrix \n",
    "\n",
    "$$R = \\beginmatrix I & -2\\r \\\\ \\vec 0\\trans & \\r\\trans \\r \\endmatrix,$$\n",
    "\n",
    "then\n",
    "\n",
    "$$\\newcommand {\\na}{*} RG = \n",
    "\\beginmatrix \n",
    "g_{11}^2 - 2 r_1 g_1 & \\na & \\cdots & \\na \\\\\n",
    "\\na & g_{22}^2 - 2r_2 g_2 & \\cdots & \\na \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\na & \\na & \\cdots & \\r\\trans\\r\n",
    "\\endmatrix $$ \n",
    "\n",
    "The trace of this matrix is then clearly equal to the original problem. \n",
    "\n",
    "$$\\trace{RG} = \\sum_{i=1}^m \\(g_{i}^2 - 2 r_i g_i\\) + \\r\\trans \\r = \\sum_{i=1}^m \\(g_{i}^2 - 2 r_i g_i + r_i^2\\)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the equality constraints, we can repeat the above process. First, we define a matrix \n",
    "\n",
    "$$A_i = \\beginmatrix \n",
    "I & -2 \\a_i \\\\ \n",
    "\\vec0 \\trans & \\a_i\\trans\\a_i\n",
    "\\endmatrix $$\n",
    "\n",
    "Then $$\\trace{A_iX} = \\twonorm{\\x-\\a_i}^2$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, every column in $X$ and $G$ a is a product multiple of the last (as well as all the others, but the last is the simplest to see), so we add the following two constraints.\n",
    "\n",
    "$$ \\rank(X) = 1 \\and \\rank(G) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together, our optimization problem becomes\n",
    "\n",
    "$$\\beginalign\n",
    "\\minimize{X\\in \\symmetricmatrices[n+1]\\\\G \\in \\symmetricmatrices[m+1]} &\\trace{RG} \\\\\n",
    "\\subjectto \n",
    "    &G_{ii} = \\trace{A_iX}, \\quad \\for i = 1, \\dots, m+1 \\\\ \n",
    "    &\\rank(X) = 1 \\\\\n",
    "    &\\rank(G) = 1 \\\\\n",
    "\\endalign\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a.2) Is the resulting optimization problem in (a.1) convex? Why/why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the objective function and the equality constraints are all affine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a.3) If you think the problem in (a.1) is a convex optimization problem, then what kind is it? If you think it is not, then derive a (sub-optimal) convex relaxation of this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function and constraints are affine, so this is a LP problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, solving the formulation given in part (a) is difficult. A different approach is to consider the \"squared range\", instead of \"range\", as the measurement. This amounts to solving\n",
    "\n",
    "$$\\minimize{x\\in\\mathbb{R}^{n}} \\underbrace{\\displaystyle\\sum_{i=1}^{m}\\left(\\twonorm{ x - a_{i} }^{2} \\: - \\: r_{i}^{2} \\right)^{2}}_{f_{0}(x)},$$\n",
    "\n",
    "or equivalently,\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&\\minimize{\\x\\in\\mathbb{R}^{n}, \\alpha\\in\\mathbb{R}}\\:\\displaystyle\\sum_{i=1}^{m}\\left(\\alpha - 2 \\vec a_{i}\\trans\\x + \\twonorm {\\vec a_{i}}^{2} - r_{i}^{2}\\right)^{2},\\\\\n",
    "&\\subjectto \\x\\trans\\x \\:=\\: \\alpha.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Introducing $y := \\begin{pmatrix}x\\\\ \\alpha\\end{pmatrix}\\in\\reals^{n+1}$, rewrite the above problem as\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&\\minimize{\\y\\in\\reals^{n+1}}\\twonorm{ A\\y - \\vec b}^{2},\\\\\n",
    "&\\subjectto \\y\\trans C\\y + 2\\vec d\\trans \\y \\:=\\: 0.\n",
    "\\end{aligned}$$\n",
    "\n",
    "In other words, express $A, \\vec b, C, \\vec d$ as function of the problem data: $r_{1}^{2},...,r_{m}^{2}$, and $\\vec a_{1},\\dots,\\vec a_{m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "$$\n",
    "\\newcommand {\\a}{\\vec a}\n",
    "\\newcommand {\\b}{\\vec b}\n",
    "\\newcommand {\\d}{\\vec d}\n",
    "A = \\beginmatrix \n",
    "-2 \\a_1\\trans & 1 \\\\\n",
    "-2 \\a_2\\trans & 1 \\\\\n",
    "\\vdots \\\\ \n",
    "-2 \\a_m\\trans & 1 \n",
    "\\endmatrix\n",
    "\\and \n",
    "\\b_i = r_i^2 - \\twonorm{\\a_i}^2\n",
    "\\and C = \\beginmatrix I & \\vec 0 \\\\ \\vec 0\\trans & 0 \\endmatrix \n",
    "\\and \n",
    "\\d = \\beginmatrix \\vec 0 \\\\ -\\half \\endmatrix \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Proof "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ A \\y - \\b = -2 \\a\\trans_i \\x + \\alpha - (r_i^2 - \\twonorm{a_i}^2) \\implies \\twonorm{A \\y - \\b}^2 = \\sum_{i=1}^n\\(\\alpha - 2 \\a\\trans_i \\x + \\twonorm{\\a_i}^2 - r_i^2 \\)^2$$\n",
    "and\n",
    "$$\n",
    "\\y\\trans C \\y = \\x\\trans \\x \\and 2 \\d\\trans \\y = 2\\alpha \\frac{-1}{2} = -\\alpha \\implies \\y\\trans C \\y + 2 \\d\\trans \\y = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## (c) (10 points) Is the optimization problem derived in part (b) convex? Why/why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "No, because a convex optimization problem can only have equality constraints that are affine but the problem in part (b) has quadratic equality constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) (20 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem derived in part (b) as primal problem. This primal problem enjoys zero duality gap since it amounts to minimizing a quadratic function subject to single quadratic constraint (generalized trust-region problem, see e.g., Lecture 12 notes, p.11-12 for trust region problem). \n",
    "\n",
    "Thanks to zero duality gap, one possible line of attack to solve the primal in part (b), is to first derive its Lagrange dual problem, solve that via cvxpy, and then invoke strong duality. Using this strategy, compute the optimal estimate of the source location $x^{\\rm{opt}}\\in\\mathbb{R}^{2}$, for $m=5$ sensors located at\n",
    "\n",
    "$$a_{1} = \\begin{pmatrix} 1.8\\\\2.5\\end{pmatrix}, \\quad a_{2} = \\begin{pmatrix} 2.0\\\\1.7\\end{pmatrix}, \\quad a_{3} = \\begin{pmatrix} 1.5\\\\1.5\\end{pmatrix}, \\quad a_{4} = \\begin{pmatrix} 1.5\\\\2.0\\end{pmatrix}, \\quad a_{5} = \\begin{pmatrix} 2.5\\\\1.5\\end{pmatrix},$$\n",
    "\n",
    "with $r = (2.00, 1.24, 0.59, 1.31, 1.44)$. Please supply your code in the notebook. \n",
    "\n",
    "For the above data, the following figure (credit: Boyd-Vanderberghe) shows the contour lines for the objective $f_{0}(x)$ in part (b) with sensor locations $a_{i}$ indicated by circles. \n",
    "\n",
    "<img width=\"350\" src=\"AMS229F18HW6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lagrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\W}{\\(A\\trans A - \\nu C\\)}\n",
    "\\newcommand{\\z}{\\(\\nu \\d - A\\trans \\b\\)}\n",
    "\\newcommand{\\bb}{\\twonorm{\\b}^2}\n",
    "\\beginalign \\Lagr(\\y, \\nu) \n",
    "&= \\twonorm{A \\y - \\b}^2 + \\nu\\(\\y\\trans  C \\y + 2 \\d\\trans \\y\\) \\\\\n",
    "&= \\y\\trans \\W \\y + 2\\y\\trans \\(\\nu \\d\\trans - \\b\\trans A \\)\\y + \\bb \\\\\n",
    "&= \\y\\trans \\W \\y + 2\\y\\trans \\z + \\bb \n",
    "\\endalign$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lagrange Dual\n",
    "$$ \n",
    "g^*(\\nu) = \\inf_\\y\\(\\y\\trans \\W \\y + 2\\y\\trans \\z + \\bb \\) $$\n",
    "\n",
    "We can find the infimum analytically by finding an expression of $\\y = \\ystar$ such that $g^*(\\nustar) = 0$\n",
    "\n",
    "$$\n",
    "\\newcommand {\\Wstar}{\\(A\\trans A - \\nustar C\\)}\n",
    "\\newcommand {\\zstar}{\\(\\nustar \\d - A\\trans \\b\\)}\n",
    "\\newcommand {\\ystarvalue}{-\\W \\invs \\zstar }\n",
    "\\beginalign\n",
    "0 &= \\del\\(\\ystartrans \\Wstar \\y + 2 \\ystartrans \\zstar + \\bb \\) \\\\\n",
    "&= 2 \\Wstar \\ystar + 2 \\zstar\n",
    "\\endalign\n",
    "$$\n",
    "\n",
    "Therefore\n",
    "$$\\ystar = \\ystarvalue$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By substituting into the Lagrange, we get \n",
    "\n",
    "$$\\beginalign \n",
    "\\gstar(\\nustar) \n",
    "&= \\inf_{\\y}(\\Lagr) \\\\\n",
    "&= \\(\\ystarvalue\\)\\trans \\W \\(\\ystarvalue\\) + 2\\(\\nu \\d\\trans - \\b\\trans A \\)\\(\\ystarvalue\\) + \\twonorm{\\b}^2 \\\\\n",
    "&= \\(\\nu \\d\\trans - \\b\\trans A \\)\\trans \\W^{(-1) \\top}\\(\\nu \\d\\trans - \\b\\trans A \\) - 2\\(\\nu \\d\\trans - \\b\\trans A \\) \\W\\invs \\(\\nu \\d\\trans - \\b\\trans A \\)  + \\twonorm{\\b}^2\\\\\n",
    "&= -\\(\\nu \\d\\trans - \\b\\trans A \\)\\trans \\W\\invs \\(\\nu \\d\\trans - \\b\\trans A \\) + \\twonorm{\\b}^2\n",
    "\\endalign$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use *cvxpy* to find the maximum of $g(\\nustar)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A $=$ $\\begin{bmatrix}-3.6 & -5 & 1 \\\\ -4 & -3.4 & 1 \\\\ -3 & -3 & 1 \\\\ -3 & -4 & 1 \\\\ -5 & -3 & 1\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**b** $=$ $\\begin{bmatrix}-5.49 \\\\ -5.3524 \\\\ -4.1519 \\\\ -4.5339 \\\\ -6.4264\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "C $=$ $\\begin{bmatrix}1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**d** $=$ $\\begin{bmatrix}0 \\\\ 0 \\\\ -0.5\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = 5\n",
    "n = 2\n",
    "r = [2.00,1.24,0.59,1.31,1.44]\n",
    "# Defining as row vectors for convinence. \n",
    "a1 = [1.8, 2.5]\n",
    "a2 = [2.0, 1.7]\n",
    "a3 = [1.5, 1.5]\n",
    "a4 = [1.5, 2.0]\n",
    "a5 = [2.5, 1.5]\n",
    "a_vectors = np.array([a1, a2, a3, a4, a5])\n",
    "A = np.concatenate( (-2*a_vectors, np.ones((m, 1))), axis=1) \n",
    "b = np.zeros((m, 1))\n",
    "for i in range(m):\n",
    "        b[i] = np.square(r[i]) - np.square(LA.norm(a_vectors[i]))\n",
    "C =  np.array([[1.0, 0.0, 0.0],[0.0, 1.0, 0.0], [0.0, 0.0, 0.0]])\n",
    "d =  np.array([[0.0], [0.0], [-0.5]])\n",
    "\n",
    "def y(nu):\n",
    "    W = np.dot(A.T, A) + nu * C\n",
    "    z = nu * d - (A.T).dot(b)\n",
    "    return -LA.pinv(W).dot(z)\n",
    "\n",
    "display_matrix(A, \"A\")  \n",
    "display_matrix(b, \"**b**\")  \n",
    "display_matrix(C, \"C\")  \n",
    "display_matrix(d, \"**d**\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solve Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution, nu =  0.5894762017936269\n",
      "opt_val:  0.30720426573182635\n"
     ]
    }
   ],
   "source": [
    "nu = cvx.Variable()\n",
    "W = np.dot(A.T, A) + nu * C\n",
    "z = nu * d - np.dot(A.T, b)\n",
    "objective_funct = cvx.Minimize(cvx.matrix_frac(z, W))\n",
    "prob = cvx.Problem(objective_funct)\n",
    "opt_val = prob.solve(solver=cvx.CVXOPT)\n",
    "print(\"solution, nu = \", nu.value)\n",
    "print(\"opt_val: \", -opt_val + np.square(LA.norm(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate  $\\ystar$ as a function of $\\nustar$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$\\y^*$ $=$ $\\begin{bmatrix}1.327 \\\\ 0.645 \\\\ 2.176\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ystar = -np.dot(LA.inv(W.value),z.value)\n",
    "display_matrix(np.array(ystar), r\"$\\y^*$\", \"%.3f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, $\\y = \\beginmatrix\\x \\\\ \\alpha \\endmatrix$, so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$\\x^*$ $=$ $\\begin{bmatrix}1.327 \\\\ 0.645\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_matrix(np.array(ystar[0:2]), r\"$\\x^*$\", \"%.3f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) (25 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to solve for the primal in part (b) is the following. Use the KKT condition to write the primal argmin $x^{\\rm{opt}}$ as an explicit function of the optimal Lagrange multiplier $\\nu^{\\rm{opt}}$. Then derive a nonlinear algebraic equation of the form $\\phi(\\nu^{\\rm{opt}}) = 0$ and solve the same using bisection method for the numerical data given in part (d). Finally, compute and compare $x^{\\rm{opt}}$ obtained from the KKT analysis with that obtained from part (d). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Solution** \n",
    "\n",
    "We can use the KKT conditions because $f_0, f_1 \\in C^1$ and strong duality holds as stated in part (d). Therefore, \n",
    "\n",
    "$$\\beginalign \n",
    "0 &= \\del_\\x L \\\\\n",
    "&= \\del f_o(\\y^*) + \\nu^* \\del h(\\y^*) \\\\\n",
    "&= \\del\\(\\twonorm{A \\y^* - \\b}^2\\ + \\nu^*(\\y^{*\\top}C \\y^* + 2 \\d\\trans \\y^*) \\) \\\\\n",
    "&= \\del\\( \\y^* (A\\trans A + \\nu C) \\y^* + 2(\\nu^*\\d - \\b\\trans A) \\y^*+ \\b\\trans\\b) \\) \\\\\n",
    "&= 2 (A\\trans A + \\nu^* C) \\y^* + 2(\\nu^*\\d - \\b\\trans A)\n",
    "\\endalign $$\n",
    "\n",
    "We can then solve for $\\y^*$:\n",
    "\n",
    "$$\\y^* = \\(A\\trans A + \\nu^* C\\)\\invs \\(\\b\\trans A - \\nu^*\\d\\)$$\n",
    "\n",
    "To simplify, we take \n",
    "\n",
    "$$W = \\W \\and \\vec z = \\z,$$\n",
    "\n",
    "and plug $\\ystar$ into Lagrangian, creating a function of $\\nu$ which we call $g^*(\\nustar)$. \n",
    "\n",
    "$$\\gstar(\\nustar) \\definedas\n",
    "\\Lagr\\(\\ystar(\\nustar), \\nustar\\) = -\\vec z\\trans W\\invs \\vec z + \\twonorm{\\b}^2$$ \n",
    "\n",
    "Now, $\\gstar(\\cdot)$ is concave and differentiable, so we can find the maximum point by finding the root of $\\derivative{\\gstar}{\\nustar}$. Because it is a concave function, we know that its derivative will have at most one zero (or, potentially, one continuous interval where the derivative is zero, but in that case the maximum value of $g^*$ will be achieved at every point in that interval)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\newcommand {\\ddnu}[1]{\\derivative{#1}{\\nustar}}\n",
    "\\beginalign \n",
    "\\derivative{\\gstar}{\\nustar} &= \\ddnu{}\\(-\\vec z W\\invs \\vec z\\) \\\\\n",
    "&= -\\( \\ddnu{\\vec z\\trans} W\\invs \\vec z + \\vec z \\trans\\ddnu{W\\invs}\\vec z + \\vec z\\trans W \\invs \\ddnu{\\vec z} \\) \n",
    "\\endalign$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate:\n",
    "\n",
    "$$\\beginalign \n",
    "\\ddnu{\\vec z} &= \\ddnu{}\\( \\nustar \\d - A\\trans \\b \\) \\\\ \n",
    "& = \\d \\\\\n",
    "\\\\\n",
    "\\ddnu{W\\invs} &= -W\\invs \\ddnu{W} W\\invs \\\\ \n",
    "& = -W\\invs \\ddnu{}\\W W\\invs \\\\ \n",
    "& =  -W\\invs C W\\invs \n",
    "\\endalign$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plugging in above, we get\n",
    "\n",
    "$$\\ddnu{\\gstar} = -\\d W\\invs \\vec z + \\vec z \\trans W\\invs C W\\invs \\vec z - \\vec z \\trans W\\invs \\d = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then find the roots of $\\ddnu{\\gstar}$ using a bisection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose two (distant) values on either side of expected range values\n",
    "def find_zero(f, expected_range, tolerance):\n",
    "    # Implmented using a bisection algorithm.\n",
    "    x_left_start = expected_range[0]\n",
    "    x_right_start = expected_range[1]\n",
    "    x1 = x_left_start\n",
    "    x2 = x_right_start\n",
    "    \n",
    "    for n in range(100):\n",
    "        mid = (x1 + x2 ) / 2.0\n",
    "        \n",
    "        sign_change_in_left = f(x1)*f(mid) <= 0\n",
    "        sign_change_in_right = f(x2)*f(mid) <= 0\n",
    "        \n",
    "        if not sign_change_in_left and not sign_change_in_right:\n",
    "            raise Exception(\"No sign changes in region: \" + str(expected_range))\n",
    "        \n",
    "        if sign_change_in_left:\n",
    "            if abs(x2 - mid) < tolerance:\n",
    "                return mid\n",
    "            x2 = mid\n",
    "        else:\n",
    "            if abs(x1 - mid) < tolerance:\n",
    "                return mid\n",
    "            x1 = mid\n",
    "                \n",
    "    raise Exception(\"Convergence was not acheived in 100 iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(nu):\n",
    "    z = nu * d - (A.T).dot(b)\n",
    "    W = np.dot(A.T, A) + nu * C\n",
    "    return (-(z.T).dot(LA.pinv(W)).dot(z) + (b.T).dot(b))[0][0]\n",
    "\n",
    "def neg_g(nu):\n",
    "    return -g(nu)\n",
    "\n",
    "def dg_dnu(nu): \n",
    "    W = np.dot(A.T, A) + nu * C\n",
    "    Winvs = LA.inv(W)\n",
    "    z = nu * d - (A.T).dot(b)\n",
    "    return -(  (d.T).dot(Winvs).dot(z) \n",
    "             - (z.T).dot(Winvs).dot(C).dot(Winvs).dot(z) \n",
    "             + (z.T).dot(Winvs).dot(d)  )[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero at nu = 0.5896687507629395\n",
      "optimal value: p* = 0.30720404327706774\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "$y^*$ $=$ $\\begin{bmatrix}1.3269 \\\\ 0.644604 \\\\ 2.17626\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero = find_zero(dg_dnu, (-1000, 1000), 0.0001)\n",
    "print(\"Zero at nu = \" + str(zero))\n",
    "print(\"optimal value: p* = \" + str(g(zero)))\n",
    "display_matrix(y(zero), \"$y^*$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that $y = \\beginmatrix \\x \\\\ \\alpha \\endmatrix$, so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$x^*$ $=$ $\\begin{bmatrix}1.3269 \\\\ 0.6446\\end{bmatrix}$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_matrix(y(zero)[0:2], \"$x^*$\", \"%.4f\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values agree with those found in part (d)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "64",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
